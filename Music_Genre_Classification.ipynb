{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "#...\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/envs/myenv/lib/python3.6/site-packages/ipykernel_launcher.py:8: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n",
      "/Applications/anaconda/envs/myenv/lib/python3.6/site-packages/ipykernel_launcher.py:9: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  if __name__ == '__main__':\n",
      "/Applications/anaconda/envs/myenv/lib/python3.6/site-packages/ipykernel_launcher.py:10: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/Applications/anaconda/envs/myenv/lib/python3.6/site-packages/ipykernel_launcher.py:11: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4363, 11)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAADZZJREFUeJzt3X+o3Xd9x/Hna41uUzeakrR0SVi6ETa7gbWE2q0wunXU/him+6PQwjSUQvZH3XQII/pPhyJ0sLlNcIVMMyNzleIPGjRYQybI/tD1VkttrdJQu/aarLkurroJc93e++N+Q0+Sm9yb++N8k7yfD7iccz73c8/3cw5Nnvn+OLepKiRJ/fzU2AuQJI3DAEhSUwZAkpoyAJLUlAGQpKYMgCQ1ZQAkqSkDIElNGQBJamrd2As4mw0bNtTWrVvHXoYkXVAef/zx71fVxsXmndcB2Lp1KzMzM2MvQ5IuKEn+dSnzPAQkSU0ZAElqygBIUlMGQJKaMgCS1JQBkKSmDIAkNWUAJKkpAyBJTZ3XnwReqa27vzDKdp9/4PZRtitJ58I9AElqygBIUlMGQJKaMgCS1JQBkKSmDIAkNWUAJKkpAyBJTRkASWrKAEhSUwZAkpoyAJLU1KIBSLIlyZeTPJPk6STvGsYvS3IwybPD7fphPEk+nORwkieTXDvxXDuH+c8m2bl2L0uStJil7AG8Arynqt4IXA/cl+RqYDdwqKq2AYeGxwC3AtuGr13AgzAfDOB+4C3AdcD9J6IhSZq+RQNQVUer6uvD/R8BzwCbgB3AvmHaPuCO4f4O4BM176vApUmuBN4KHKyq41X1A+AgcMuqvhpJ0pKd0zmAJFuBNwNfA66oqqMwHwng8mHaJuDFiR+bHcbONC5JGsGSA5DkDcBngHdX1Q/PNnWBsTrL+Knb2ZVkJsnM3NzcUpcnSTpHSwpAktcw/5f/J6vqs8PwS8OhHYbbY8P4LLBl4sc3A0fOMn6SqtpTVduravvGjRvP5bVIks7BUq4CCvAx4Jmq+tDEt/YDJ67k2Qk8MjH+juFqoOuBl4dDRI8CNydZP5z8vXkYkySNYCn/T+AbgLcD30zyxDD2PuAB4OEk9wIvAHcO3zsA3AYcBn4M3ANQVceTfAB4bJj3/qo6viqvQpJ0zhYNQFX9Mwsfvwe4aYH5Bdx3hufaC+w9lwVKktaGnwSWpKYMgCQ1ZQAkqSkDIElNGQBJasoASFJTBkCSmjIAktSUAZCkpgyAJDVlACSpKQMgSU0ZAElqygBIUlMGQJKaMgCS1JQBkKSmDIAkNWUAJKkpAyBJTRkASWrKAEhSUwZAkpoyAJLUlAGQpKYMgCQ1ZQAkqSkDIElNGQBJasoASFJTBkCSmjIAktSUAZCkpgyAJDVlACSpKQMgSU0ZAElqygBIUlMGQJKaWjQASfYmOZbkqYmxP0vyvSRPDF+3TXzvvUkOJ/lOkrdOjN8yjB1Osnv1X4ok6VwsZQ/g48AtC4z/VVVdM3wdAEhyNXAX8GvDz/xtkkuSXAJ8BLgVuBq4e5grSRrJusUmVNVXkmxd4vPtAD5VVf8NfDfJYeC64XuHq+o5gCSfGuZ+65xXLElaFSs5B/DOJE8Oh4jWD2ObgBcn5swOY2caP02SXUlmkszMzc2tYHmSpLNZbgAeBH4ZuAY4CvzlMJ4F5tZZxk8frNpTVduravvGjRuXuTxJ0mIWPQS0kKp66cT9JH8HfH54OAtsmZi6GTgy3D/TuCRpBMvaA0hy5cTD3wdOXCG0H7gryU8nuQrYBvwL8BiwLclVSV7L/Ini/ctftiRppRbdA0jyEHAjsCHJLHA/cGOSa5g/jPM88IcAVfV0koeZP7n7CnBfVf3v8DzvBB4FLgH2VtXTq/5qJElLtpSrgO5eYPhjZ5n/QeCDC4wfAA6c0+okSWvGTwJLUlMGQJKaMgCS1JQBkKSmDIAkNWUAJKkpAyBJTRkASWrKAEhSUwZAkpoyAJLUlAGQpKYMgCQ1ZQAkqSkDIElNGQBJasoASFJTBkCSmjIAktSUAZCkpgyAJDVlACSpKQMgSU0ZAElqygBIUlMGQJKaMgCS1JQBkKSmDIAkNWUAJKkpAyBJTRkASWrKAEhSUwZAkpoyAJLUlAGQpKYMgCQ1ZQAkqalFA5Bkb5JjSZ6aGLssycEkzw6364fxJPlwksNJnkxy7cTP7BzmP5tk59q8HEnSUi1lD+DjwC2njO0GDlXVNuDQ8BjgVmDb8LULeBDmgwHcD7wFuA64/0Q0JEnjWDQAVfUV4PgpwzuAfcP9fcAdE+OfqHlfBS5NciXwVuBgVR2vqh8ABzk9KpKkKVruOYArquoowHB7+TC+CXhxYt7sMHamcUnSSFb7JHAWGKuzjJ/+BMmuJDNJZubm5lZ1cZKkVy03AC8Nh3YYbo8N47PAlol5m4EjZxk/TVXtqartVbV948aNy1yeJGkxyw3AfuDElTw7gUcmxt8xXA10PfDycIjoUeDmJOuHk783D2OSpJGsW2xCkoeAG4ENSWaZv5rnAeDhJPcCLwB3DtMPALcBh4EfA/cAVNXxJB8AHhvmvb+qTj2xLEmaokUDUFV3n+FbNy0wt4D7zvA8e4G957Q6SdKa8ZPAktSUAZCkpgyAJDVlACSpKQMgSU0ZAElqygBIUlMGQJKaMgCS1JQBkKSmDIAkNWUAJKkpAyBJTRkASWrKAEhSUwZAkpoyAJLUlAGQpKYMgCQ1ZQAkqSkDIElNGQBJasoASFJTBkCSmjIAktSUAZCkpgyAJDVlACSpKQMgSU0ZAElqygBIUlPrxl7AxWjr7i+Mtu3nH7h9tG1LurC4ByBJTRkASWrKAEhSUwZAkpoyAJLUlAGQpKYMgCQ1taIAJHk+yTeTPJFkZhi7LMnBJM8Ot+uH8ST5cJLDSZ5Mcu1qvABJ0vKsxh7Ab1fVNVW1fXi8GzhUVduAQ8NjgFuBbcPXLuDBVdi2JGmZ1uIQ0A5g33B/H3DHxPgnat5XgUuTXLkG25ckLcFKA1DAl5I8nmTXMHZFVR0FGG4vH8Y3AS9O/OzsMHaSJLuSzCSZmZubW+HyJElnstLfBXRDVR1JcjlwMMm3zzI3C4zVaQNVe4A9ANu3bz/t+5Kk1bGiPYCqOjLcHgM+B1wHvHTi0M5we2yYPgtsmfjxzcCRlWxfkrR8yw5Aktcn+bkT94GbgaeA/cDOYdpO4JHh/n7gHcPVQNcDL584VCRJmr6VHAK6AvhckhPP849V9cUkjwEPJ7kXeAG4c5h/ALgNOAz8GLhnBduWJK3QsgNQVc8Bb1pg/N+BmxYYL+C+5W5PkrS6/CSwJDVlACSpKQMgSU0ZAElqygBIUlMGQJKaMgCS1JQBkKSmDIAkNWUAJKkpAyBJTa30/weg88zW3V8YZbvPP3D7KNuVtHzuAUhSUwZAkpoyAJLUlAGQpKYMgCQ15VVA0jJ5xZUudAZAq8K/DKULj4eAJKkpAyBJTXkISBe0sQ49SRcD9wAkqSn3ACQtmSf7Ly7uAUhSUwZAkpoyAJLUlAGQpKY8CSxdYLz0VavFPQBJasoASFJTBkCSmjIAktSUJ4ElnffGPPF9MX8K2QBI0llczL/+wkNAktSUAZCkpgyAJDU19QAkuSXJd5IcTrJ72tuXJM2bagCSXAJ8BLgVuBq4O8nV01yDJGnetPcArgMOV9VzVfUT4FPAjimvQZLE9AOwCXhx4vHsMCZJmrJpfw4gC4zVSROSXcCu4eF/JvnOmq9qbW0Avj/2Is4jvh8n8/14le/FhPz5it6PX1zKpGkHYBbYMvF4M3BkckJV7QH2THNRaynJTFVtH3sd5wvfj5P5frzK9+Jk03g/pn0I6DFgW5KrkrwWuAvYP+U1SJKY8h5AVb2S5J3Ao8AlwN6qenqaa5AkzZv67wKqqgPAgWlvd0QXzeGsVeL7cTLfj1f5Xpxszd+PVNXisyRJFx1/FYQkNWUA1kiSLUm+nOSZJE8nedfYaxpbkkuSfCPJ58dey9iSXJrk00m+Pfw38htjr2lMSf5k+HPyVJKHkvzM2GuapiR7kxxL8tTE2GVJDiZ5drhdv9rbNQBr5xXgPVX1RuB64D5/7QXvAp4ZexHnib8BvlhVvwq8icbvS5JNwB8D26vq15m/QOSucVc1dR8HbjllbDdwqKq2AYeGx6vKAKyRqjpaVV8f7v+I+T/gbT/1nGQzcDvw0bHXMrYkPw/8FvAxgKr6SVX9x7irGt064GeTrANexymfD7rYVdVXgOOnDO8A9g339wF3rPZ2DcAUJNkKvBn42rgrGdVfA38K/N/YCzkP/BIwB/z9cEjso0leP/aixlJV3wP+AngBOAq8XFVfGndV54UrquoozP+DErh8tTdgANZYkjcAnwHeXVU/HHs9Y0jye8Cxqnp87LWcJ9YB1wIPVtWbgf9iDXbvLxTDse0dwFXALwCvT/IH466qBwOwhpK8hvm//D9ZVZ8dez0jugF4W5Lnmf8NsL+T5B/GXdKoZoHZqjqxR/hp5oPQ1e8C362quar6H+CzwG+OvKbzwUtJrgQYbo+t9gYMwBpJEuaP8T5TVR8aez1jqqr3VtXmqtrK/Mm9f6qqtv/Cq6p/A15M8ivD0E3At0Zc0theAK5P8rrhz81NND4pPmE/sHO4vxN4ZLU3MPVPAjdyA/B24JtJnhjG3jd8Elr6I+CTw+/Eeg64Z+T1jKaqvpbk08DXmb967hs0+1RwkoeAG4ENSWaB+4EHgIeT3Mt8JO9c9e36SWBJ6slDQJLUlAGQpKYMgCQ1ZQAkqSkDIElNGQBJasoASFJTBkCSmvp/gZQjcOpFTUwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the data and cleanup\n",
    "x_test_df = pd.read_csv('test_data.csv', header = None)\n",
    "y_test_df = pd.read_csv('dummy_solution_accuracy.csv')\n",
    "x_train_df = pd.read_csv('train_data.csv', header = None)\n",
    "y_train_df = pd.read_csv('train_labels.csv', header = None)\n",
    "\n",
    "#Convert the dataframe to numpy matrix\n",
    "x_test = x_test_df.as_matrix()\n",
    "y_test = y_test_df.as_matrix()\n",
    "x_train = x_train_df.as_matrix()\n",
    "y_train = y_train_df.as_matrix()\n",
    "\n",
    "\n",
    "y_train_dummy =  keras.utils.to_categorical(y_train)\n",
    "#test_label_dummy = keras.utils.to_categorical(test_label)\n",
    "np.unique(y_train)\n",
    "plt.hist(y_train, bins = 10)\n",
    "y_train_dummy.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "553467904/553467096 [==============================] - 78s 0us/step\n"
     ]
    }
   ],
   "source": [
    "#Analysis of the input data\n",
    "# ...\n",
    "#model = Sequential()\n",
    "#model.add(Dense(300, activation='relu', input_dim=264))\n",
    "#model.add(Dense(30, activation = 'relu'))\n",
    "#model.add(Dense(11, activation='softmax'))\n",
    "#model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "#model.fit(x_train, y_train_dummy, batch_size=60, epochs=10)\n",
    "from keras.applications import VGG16, VGG19\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_model = keras.applications.vgg16.VGG16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg16_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4363/4363 [==============================] - 3s 683us/step - loss: 15.3571 - acc: 0.0472\n",
      "Epoch 2/10\n",
      "4363/4363 [==============================] - 1s 222us/step - loss: 15.3571 - acc: 0.0472\n",
      "Epoch 3/10\n",
      "4363/4363 [==============================] - 1s 231us/step - loss: 15.3571 - acc: 0.0472\n",
      "Epoch 4/10\n",
      "4363/4363 [==============================] - 1s 223us/step - loss: 15.3571 - acc: 0.0472\n",
      "Epoch 5/10\n",
      "4363/4363 [==============================] - 1s 205us/step - loss: 15.3571 - acc: 0.0472\n",
      "Epoch 6/10\n",
      "4363/4363 [==============================] - 1s 171us/step - loss: 15.3571 - acc: 0.0472\n",
      "Epoch 7/10\n",
      "4363/4363 [==============================] - 1s 185us/step - loss: 15.3571 - acc: 0.0472\n",
      "Epoch 8/10\n",
      "4363/4363 [==============================] - 1s 195us/step - loss: 15.3571 - acc: 0.0472\n",
      "Epoch 9/10\n",
      "4363/4363 [==============================] - 1s 183us/step - loss: 15.3571 - acc: 0.0472\n",
      "Epoch 10/10\n",
      "4363/4363 [==============================] - 1s 175us/step - loss: 15.3571 - acc: 0.0472\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a3cf11be0>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(300, activation='relu', input_dim=264))\n",
    "model.add(Dense(30, activation = 'relu'))\n",
    "model.add(Dense(11, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(x_train, y_train_dummy, batch_size=60, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0407e+03 2.3156e+03 2.8391e+03 ... 7.4371e-02 7.3162e-02 5.9463e-02]\n",
      " [2.3094e+03 4.7804e+03 4.0557e+03 ... 5.2523e-02 5.2357e-02 5.5297e-02]\n",
      " [2.3319e+03 4.6070e+03 4.7323e+03 ... 6.1138e-02 8.5509e-02 4.9422e-02]\n",
      " ...\n",
      " [2.6242e+03 3.6887e+03 2.1284e+03 ... 6.5561e-02 5.2131e-02 8.0473e-02]\n",
      " [2.7510e+03 3.7674e+03 3.8587e+03 ... 5.6053e-02 4.2466e-02 5.7299e-02]\n",
      " [4.6222e+03 4.4102e+03 2.1174e+03 ... 1.1781e-01 9.8176e-02 3.2360e-02]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/envs/myenv/lib/python3.6/site-packages/sklearn/utils/validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7739914425427873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/envs/myenv/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda/envs/myenv/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Logistic regression\n",
    "from sklearn.linear_model import LogisticRegression # import logistic package\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "\n",
    "logreg = LogisticRegression(C=1e5, solver='lbfgs', multi_class='multinomial')\n",
    "logreg.fit(x_train, y_train)\n",
    "predictions = logreg.predict(x_test)\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(y_test[:,1], predictions)\n",
    "report_classification = metrics.classification_report(y_test[:,1], predictions)\n",
    "score = logreg.score(x_test,y_test[:,1])\n",
    "accuracy = accuracy_score(y_test[:,1],predictions)\n",
    "print('Accuracy: '  + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5065  962  450   34   27    3    3]\n",
      " [   0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.77      0.87      6544\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      6544\n",
      "   macro avg       0.14      0.11      0.12      6544\n",
      "weighted avg       1.00      0.77      0.87      6544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix)\n",
    "print(report_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import cross_val_score\n",
    "#cross_val = cross_val_score(LogisticRegression(), x_test, y_test[:,1], scoring='accuracy', cv=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.datacamp.com/community/tutorials/random-forests-classifier-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/envs/myenv/lib/python3.6/site-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'dtypes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-b58d85c4cec6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mRF_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'dtypes'"
     ]
    }
   ],
   "source": [
    "#Testing with Random Forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "RandomForest_model = RandomForestRegressor(n_estimators=20, random_state=0)  \n",
    "RandomForest_model.fit(x_train, y_train)  \n",
    "RF_predictions = RandomForest_model.predict(x_test)  \n",
    "\n",
    "y_train.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "#print(confusion_matrix(y_test[:,1],RF_predictions))  \n",
    "#print(classification_report(y_test[:,1],RF_predictions))  \n",
    "#print(accuracy_score(y_test[:,1],RF_predictions)) \n",
    "\n",
    "y_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
